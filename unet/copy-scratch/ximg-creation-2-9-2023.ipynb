{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cb325a9",
   "metadata": {},
   "source": [
    "# Scratch \n",
    "\n",
    "For one-off image stack creation\n",
    "02-09-2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9a93c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/groups/jyeatman/software/anaconda3/envs/torch-ni-ny/lib/python3.9/site-packages/nilearn/datasets/__init__.py:93: FutureWarning: Fetchers from the nilearn.datasets module will be updated in version 0.9 to return python strings instead of bytes and Pandas dataframes instead of Numpy arrays.\n",
      "  warn(\"Fetchers from the nilearn.datasets module will be \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pipeline_utilities as pu\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "wd = '/scratch/groups/jyeatman/samjohns-projects/backups/samjohns-projects/samjohns-backups-2/data/atlas'\n",
    "val = 'hbn_sulc_mapping_val.csv'\n",
    "trn = 'hbn_sulc_mapping_trn.csv'\n",
    "\n",
    "df_val = pd.read_csv(f'{wd}/{val}')\n",
    "df_trn = pd.read_csv(f'{wd}/{trn}')\n",
    "\n",
    "df = pd.concat([df_trn, df_val])\n",
    "df.sort_values('EID', inplace=True)\n",
    "\n",
    "subjects = list(df['EID'].unique())\n",
    "\n",
    "# start = int(sys.argv[1])\n",
    "# end = int(sys.argv[2])\n",
    "start, end = 0, 1\n",
    "\n",
    "hbn_dir = '/oak/stanford/groups/jyeatman/HBN/BIDS_curated/derivatives/freesurfer'\n",
    "# hbn_subjects = [s for s in os.listdir(hbn_dir) if s[:4]=='sub-']\n",
    "\n",
    "save_base_dir = '/scratch/groups/jyeatman/samjohns-projects/data/atlas-2'\n",
    "save_x_subdir = 'xs'\n",
    "save_y_subdir = 'ys'\n",
    "save_xdir = os.path.join(save_base_dir, save_x_subdir)\n",
    "save_ydir = os.path.join(save_base_dir, save_y_subdir)\n",
    "\n",
    "save_px2v_subdir = 'px2v'\n",
    "save_pxcoord_subdir = 'pxcoord'\n",
    "save_px2v_dir = os.path.join(save_base_dir, save_px2v_subdir)\n",
    "save_pxcoord_dir = os.path.join(save_base_dir, save_pxcoord_subdir)\n",
    "\n",
    "os.makedirs(save_base_dir, exist_ok=True)\n",
    "os.makedirs(save_xdir, exist_ok=True)\n",
    "os.makedirs(save_ydir, exist_ok=True)\n",
    "os.makedirs(save_px2v_dir, exist_ok=True)\n",
    "os.makedirs(save_pxcoord_dir, exist_ok=True)\n",
    "\n",
    "parc_fn = 'lh.aparc.a2009s.annot'  # Destrieux parcellation\n",
    "curv_fn = 'lh.curv'\n",
    "mesh_fn = 'lh.inflated'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d41a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save out static todo list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c553a76c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "493"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "done_subjects = os.listdir(save_xdir)\n",
    "done_eids = [s.split('-')[1] for s in done_subjects]\n",
    "\n",
    "df.groupby('EID', as_index=False).count()\n",
    "\n",
    "df_done = pd.DataFrame({'EID': done_eids, 'Dummy': 1})\n",
    "df_counts = df_done.groupby('EID', as_index=False).count()\n",
    "subjects_done = ['sub-' + s for s in list(df_counts[df_counts['Dummy'] == 70]['EID'])]\n",
    "subjects_todo = list(set(subjects) - set(subjects_done))\n",
    "\n",
    "len(subjects_todo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7af083f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "save = True\n",
    "subjects_todo_df = pd.DataFrame({'EID': subjects_todo})\n",
    "save_fn = 'todo_subjects.csv'\n",
    "\n",
    "if save:\n",
    "    subjects_todo_df.to_csv(save_fn, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a6455d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_todo_df_loaded = pd.read_csv(save_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a84ea25",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_todo = list(subjects_todo_df_loaded['EID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ce7aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub in subjects_todo[start:end]:\n",
    "    \n",
    "    sub_df = df[df['EID'] == sub]\n",
    "    ang = list(sub_df[['Angle1', 'Angle2']].values)\n",
    "    \n",
    "    subj_fp = os.path.join(hbn_dir, sub)\n",
    "    subject_data_exists = pu.freesurfer_subject_data_exists_parc(subj_fp, [mesh_fn],\n",
    "                                                                 [curv_fn],\n",
    "                                                                 label_files=[parc_fn])\n",
    "    if not subject_data_exists:  # skip subject if required files don't exist\n",
    "        continue\n",
    "    subject_data = pu.get_freesurfer_subject_with_parc(subj_fp,\n",
    "                                                       [mesh_fn],\n",
    "                                                       [curv_fn],\n",
    "                                                       label_files=[parc_fn])\n",
    "\n",
    "    mesh = subject_data[mesh_fn]\n",
    "    curv = subject_data[curv_fn]\n",
    "    parc = subject_data[parc_fn]\n",
    "\n",
    "    # pipeline (below):\n",
    "    # 1. create plt figures\n",
    "    # 2. process (downsample, grayscale, extract channels) -> np array\n",
    "    # 3. get px2v data from coordinate images\n",
    "    \n",
    "    nangles_inner = 5\n",
    "    nangles_total = len(ang)\n",
    "    nangle_iterations = (nangles_total // nangles_inner) + 1\n",
    "\n",
    "    for i in range(nangle_iterations):\n",
    "        \n",
    "        angle_batch = ang[(nangles_inner * i) : (nangles_inner * (i + 1))]\n",
    "        if len(angle_batch) == 0:\n",
    "            break\n",
    "        \n",
    "        fig_dict = pu.make_subject_images(mesh, curv, parc, angles=angle_batch) \n",
    "        np_dict = pu.process_figs(fig_dict)\n",
    "        np_px_dict = pu.px2v_from_np_dict(np_dict, \n",
    "                                          mesh_coords=mesh.coordinates)\n",
    "        plt.close('all')  # clear all matplotlib plots to save memory\n",
    "        pu.save_subject_npys(sub, np_px_dict, save_xdir, save_ydir, \n",
    "                             save_px2v_dir=save_px2v_dir, \n",
    "                             save_pxcoord_dir=save_pxcoord_dir)\n",
    "        del np_dict  # clear dictionaries to save memory\n",
    "        del np_px_dict\n",
    "        \n",
    "    plt.close('all')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch-ni-ny]",
   "language": "python",
   "name": "conda-env-torch-ni-ny-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
